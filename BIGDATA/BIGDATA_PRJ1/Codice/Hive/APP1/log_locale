peter@peter-Aspire-ES1-512:~/hive$ bin/hive -f /home/peter/Scrivania/es1.hql

Logging initialized using configuration in jar:file:/home/peter/hive/lib/hive-common-1.0.0.jar!/hive-log4j.properties
OK
Time taken: 5.725 seconds
OK
Time taken: 1.065 seconds
Loading data to table default.prodotti_vendite
Table default.prodotti_vendite stats: [numFiles=1, numRows=0, totalSize=2370, rawDataSize=0]
OK
Time taken: 2.321 seconds
FAILED: SemanticException [Error 10001]: Line 7:55 Table not found 'numProdotti'
peter@peter-Aspire-ES1-512:~/hive$ bin/hive -f /home/peter/Scrivania/es1.hql

Logging initialized using configuration in jar:file:/home/peter/hive/lib/hive-common-1.0.0.jar!/hive-log4j.properties
OK
Time taken: 3.668 seconds
OK
Time taken: 0.687 seconds
Loading data to table default.prodotti_vendite
Table default.prodotti_vendite stats: [numFiles=1, numRows=0, totalSize=2370, rawDataSize=0]
OK
Time taken: 0.977 seconds
FAILED: SemanticException [Error 10004]: Line 8:6 Invalid table alias or column reference 'prodotto': (possible column names are: product)
peter@peter-Aspire-ES1-512:~/hive$ bin/hive -f /home/peter/Scrivania/es1.hql

Logging initialized using configuration in jar:file:/home/peter/hive/lib/hive-common-1.0.0.jar!/hive-log4j.properties
OK
Time taken: 3.622 seconds
OK
Time taken: 0.656 seconds
Loading data to table default.prodotti_vendite
Table default.prodotti_vendite stats: [numFiles=1, numRows=0, totalSize=2370, rawDataSize=0]
OK
Time taken: 1.0 seconds
Query ID = peter_20150502211313_790d13d3-0880-48f5-a2ca-26a61d907a5e
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1430593611372_0001, Tracking URL = http://peter-Aspire-ES1-512:8088/proxy/application_1430593611372_0001/
Kill Command = /home/peter/hadoop/bin/hadoop job  -kill job_1430593611372_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-05-02 21:13:55,332 Stage-1 map = 0%,  reduce = 0%
2015-05-02 21:14:07,748 Stage-1 map = 100%,  reduce = 0%
2015-05-02 21:14:21,098 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.57 sec
MapReduce Total cumulative CPU time: 6 seconds 570 msec
Ended Job = job_1430593611372_0001
Launching Job 2 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1430593611372_0002, Tracking URL = http://peter-Aspire-ES1-512:8088/proxy/application_1430593611372_0002/
Kill Command = /home/peter/hadoop/bin/hadoop job  -kill job_1430593611372_0002
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2015-05-02 21:14:39,772 Stage-2 map = 0%,  reduce = 0%
2015-05-02 21:14:51,286 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.19 sec
2015-05-02 21:15:03,403 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.47 sec
MapReduce Total cumulative CPU time: 5 seconds 470 msec
Ended Job = job_1430593611372_0002
Copying data to local directory /home/peter/Scrivania/Risultato_es1_hive
Copying data to local directory /home/peter/Scrivania/Risultato_es1_hive
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.57 sec   HDFS Read: 2594 HDFS Write: 343 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.47 sec   HDFS Read: 745 HDFS Write: 97 SUCCESS
Total MapReduce CPU Time Spent: 12 seconds 40 msec
OK
Time taken: 91.283 seconds
